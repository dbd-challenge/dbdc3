<!DOCTYPE HTML>
<html>
<head>
<meta charset="UTF-8">
<title>DSTC6 Track 3: Dialogue Breakdown Detection</title>
<link rel="stylesheet" href="css/style.css" type="text/css">
</head>

<body>
  <center><font color=red><u><a href="https://dbd-challenge.github.io/dbdc3/data/">DBDC3 complete dataset available<a></u></font></center>
<div id="header"><div><ul id="navigation">
<li class="active"><a href="http://workshop.colips.org/dstc6/index.html">DSTC6</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;></li>
<li class="active"><a href="index.html">Breakdown detection</a></li>
</ul></div></div>
<div id="adbox"><div class="clearfix">
<div><h1>Dialogue Breakdown Detection</h1>	
<img src="images/DBD.png" alt="Img" width="400">
<h2>A Task of Dialogue System Technology Challenge 6 (DSTC6)</h2>
</div></div></div>

<div id="contents">
</br></br>

<div id="about">
<h2>Task Description</h2>
<p>
The task of dialogue breakdown detection is to detect whether the system
utterance causes dialogue breakdown (a situation in a dialogue where users
cannot proceed with the conversation) in a given dialogue context. The
participants of this track will develop a dialogue breakdown detector
that outputs a dialogue breakdown label (B: breakdown, PB: possible
breakdown, or NB:Not a breakdown) and a distribution of these labels.

<h2>Provided Data for the Challenge</h2>
<img src="images/DBD-data.png" alt="Img" width="600">
<p>
Chat-oriented dialogues (dialogue history between a user and a
chat-oriented dialogue system) are annotated with breakdown labels
for each turn by muliple annotators (typically 30 annotators) as shown in the example.

<p>
See the <a href="https://dbd-challenge.github.io/dbdc3/datasets">dataset section</a> for the developement/evaluation data we provide for the challenge.
You can also download the data from this link. English and Japanese dialogues are available.

<h2>Evaluation Metrics</h2>
<p>
* Classification-related metrics:</br>
Accuracy, prevision, recall and F-measure of estimated labels.
These metrics are calculated by comparing the output of the detector
and the gold label determined by majority voting of results of several
annotators
<p>
* Distribution-related metrics:</br>
JS divergence and mean squared error to the distribution of annotated
labels. This metrics are calculated by comparing the predicted 
distribution of the labels with the distribution of annotation.

<p>
See the <a href="https://dbd-challenge.github.io/dbdc3/evaluation_metrics">evaluation metrics section</a> for the details of the evaluation matrics.
</div>

<div id="getting_started">
<h2>Getting started</h2>
<p>
  You can have a look at <a href="https://dbd-challenge.github.io/dbdc3/getting_started">this page</a> to get started on dialogue breakdown detection challenge!
  This page shows how to use the baseline and evaluate dialogue breakdown detection results.
</div>

<div id="preparation">
<h2>Getting prepared for the formal-run</h2>
<p>
You can refer to <a href="https://dbd-challenge.github.io/dbdc3/how_to_submit_runs">this page</a> to get information about how to submit your runs
at the formal-run.
</div>

<div id="schedule">
<h2>Schedule</h2>
<span><table style="width:100%">
<tr><td width="50%" valign="top">
<p>
* Jun 1 2017: Training Data Release</br>
* <S>Aug 28 2017</S> Sept 8 2017 (extended): The Deadline of Registration</br>
* Sep 17 2017: Additional Development Data Release</br>
* <S>Sep 25 2017</S> Oct 9 2017 (extended): Test Data Release</br>
* <S>Oct 8 2017</S> <S>Oct 13</S> <font color=red>Oct 14 2017 (extended)</font>: The Deadline of Results Submission</br>
* Oct 31 2017: The Deadline of Paper Submission</br>
<font color=red>These dates are subject to change.</font>
</div>

<div id="sponsors">
  <h2>Sponsors</h2>
<!--  
<p>
DBDC3 organizers are looking for sponsors. Please see <a href="https://dbd-challenge.github.io/dbdc3/sponsors_jp.html">here (Japanese)</a> for the details.</br>
</br>
-->
We gratefully acknowledge the generous support provided by the following:
</br>
<span><table style="width:100%">
<tr>
 <a href="https://www.d-itlab.co.jp/?lang=en"><img src="images/IT_LAB_logo_20111221.png" alt="Img" width="300" hspace="30"></a>
 <a href="http://nextremer.com/en/"><img src="images/nextremer_color01.png" alt="Img" width="300"></a>
 <a href="http://www.jp.honda-ri.com/english"><img src="images/HRI.jpg" alt="Img" width="300" hspace="30"></a>
 <img src="images/docomo.JPG" alt="Img" width="300">
</tr>
</table>
</div>
<div>
<br>
This track is endorsed by <a href="https://jsai-slud.github.io/sig-slud/">Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIG-SLUD)</a> of <a href="https://www.ai-gakkai.or.jp/en/">the Japanese Society of Artificial Intelligence (JSAI)</a>.
</div>

</br>
</br>
<div id="organizer">
<h2>Task Organizers</h2>
<p>
* Ryuichiro Higashinaka (NTT)</br>
* Kotaro Funakoshi (Kyoto University/Honda Research Institute Japan)</br>
* Michimasa Inaba (Hiroshima City University)</br>
* Yuiko Tsunomori (NTT Docomo)</br>
* Tetsuro Takahashi (Fujitsu)</br>
* Nobuhiro Kaji (Yahoo Japan Corporation)</br>
</div>
<p>
  Contact us by: dbdc3-organizers<at>googlegroups.com
</body>

</html>
